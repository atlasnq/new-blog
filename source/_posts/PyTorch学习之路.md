---
title: PyTorchå­¦ä¹ ä¹‹è·¯
date: 2019-06-20 21:01:34
tags: [Pytorch,Deep Learning,å­¦ä¹ ç¬”è®°]
categories: Pytorchå­¦ä¹ ç¬”è®°
comments: true
urlname: learning-PyTorch
copyright: true
---



{% cq %}å°†PyTorchçš„å­¦ä¹ è¿‡ç¨‹è®°å½•ä¸‹æ¥ã€‚ {% endcq %}

<!--more-->



# ä»€ä¹ˆæ˜¯PyTorch



## å…¥é—¨

### å¼ é‡ä¸æ“ä½œ

```python
import torch
# å¼ é‡
# =============================================================================
x = torch.Tensor(5,3)
print(x)
 #print(x.size(),type(x.size()))
 
# æ“ä½œ
y = torch.rand(5,3)
# # =============================================================================
  # æ³•1
print(x + y)
  # æ³•2
print(torch.add(x,y))
  
  # å®šä¹‰ä¸€ä¸ªè¾“å‡ºå¼ é‡
result = torch.Tensor(5,3)
torch.add(x,y, out = result)
print(result)
  # in-placeè¿½åŠ 
y.add_(x)
print(y)
# # =============================================================================
print(y)
 #x.copy_(y)
 #print(x)
x.t_()
print(x)
print(x[:,1])
# =============================================================================
```

æ³¨æ„ï¼štorchåŒ…ä¸­å¸¦æœ‰ä¸‹åˆ’çº¿çš„opè¯´æ˜æ˜¯å°±åœ°è¿›è¡Œçš„

## Nmupyè½¬æ¢

### å°†Torchå¼ é‡è½¬åŒ–ä¸ºnumpyæ•°ç»„

```python
import torch
# =============================================================================
  # Nmupy è½¬æ¢
a = torch.ones(5)
print(a)
b = a.numpy()
print(b)
 # å½“ç»™tensor aåˆ—è¡¨çš„æ¯ä¸ªå€¼åŠ ä¸€ï¼Œ numpysåˆ—è¡¨ä¸­çš„æ¯ä¸ªå€¼åŠ ä¸€
a.add_(1)
print(a)
print(b) 
```



### å°†numpyæ•°ç»„è½¬åŒ–ä¸ºTorchå¼ é‡

```python
import torch
# =============================================================================
# å°†numpyæ•°ç»„è½¬æ¢æˆTorchå¼ é‡
import numpy as np
a = np.ones(5)
b = torch.from_numpy(a)
np.add(a, 1, out=a)
print(a)
print(b)
a[0] = 333
print(a)
print(b)
## ç»“è®ºå’Œä¸Šé¢ä¸€æ ·ï¼Œæ— è®ºæ˜¯ä»tensorè½¬æ¢æˆnumpy è¿˜æ˜¯åè¿‡æ¥ï¼Œéƒ½æ˜¯ä¸€ä¸ªå†…å®¹ä¿®æ”¹ï¼Œå¦ä¸€ä¸ªä¹Ÿä¼šå˜
 
# =============================================================================
```



## CUDAä¼ æ„Ÿå™¨

cudaä¼ æ„Ÿå™¨æ˜¯ä¸€ä¸ªåŸºäºPythonçš„ç§‘å­¦è®¡ç®—åŒ…ï¼Œä¸»è¦åˆ†å…¥å¦‚ä¸‹2éƒ¨åˆ†ï¼š

- ä½¿ç”¨GPUçš„åŠŸèƒ½ä»£æ›¿numpy
- ä¸€ä¸ªæ·±åˆ»çš„å­¦ä¹ ç ”ç©¶å¹³å°ï¼Œæä¾›æœ€å¤§çš„çµæ´»æ€§å’Œé€Ÿåº¦

```python
# CUDAä¼ æ„Ÿå™¨
import torch
x = torch.Tensor(5,3)
y = torch.rand(5,3)
if torch.cuda.is_available():  # åˆ¤æ–­cudaæ˜¯å¦å¯ç”¨
  x = x.cuda()
  print(x)
  y = y.cuda()
  x + y
```



# Autogradï¼šè‡ªåŠ¨åˆ†åŒ–

autogradåŒ…æ˜¯`PyTorch`æ‰€æœ‰ç¥ç»ç½‘ç»œçš„æ ¸å¿ƒã€‚

`autograd`åŒ…ä¸º`Tensors`ä¸Šçš„æ‰€æœ‰æ“ä½œæä¾›äº†è‡ªåŠ¨åŒºåˆ†ã€‚å®ƒæ˜¯ä¸€ä¸ªé€ä¸ªè¿è¡Œçš„æ¡†æ¶ï¼Œè¿™æ„å‘³ç€æ‚¨çš„`backprop`ç”±æ‚¨çš„ä»£ç è¿è¡Œå®šä¹‰ï¼Œæ¯ä¸€æ¬¡è¿­ä»£éƒ½å¯ä»¥ä¸åŒã€‚



## å˜é‡

`autograd.Variable`æ˜¯åŒ…çš„**ä¸­å¤®ç±»**ã€‚å®ƒåŒ…å«ä¸€ä¸ª`Tensor`ï¼Œå¹¶æ”¯æŒå‡ ä¹æ‰€æœ‰å®šä¹‰çš„æ“ä½œã€‚å®Œæˆè®¡ç®—åï¼Œå¯ä»¥è°ƒç”¨`.backward()`å¹¶è‡ªåŠ¨è®¡ç®—æ‰€æœ‰æ¢¯åº¦ã€‚



å˜é‡ä¸å˜é‡æ˜¯æœ‰åˆ›é€ å…³ç³»çš„ï¼Œä½ å¯ä»¥å¯¹è¿™äº›å…³ç³»ç»„æˆçš„å‡½æ•°æ±‚å¯¼ã€‚

åˆ›é€ ä¸€ä¸ªå˜é‡ï¼š

```python
import torch
from torch.autograd import Variable
x = Variable(torch.ones(2,2),requires_grad= True)
print(x)
```

<u>è¾“å‡º</u>ï¼š

```python
tensor([[1., 1.],
        [1., 1.]], requires_grad=True)
```

åšä¸€ä¸ªå˜é‡çš„æ“ä½œï¼š

```python
y = x + 2
print(y)
```

<u>è¾“å‡º</u>ï¼š

```python
tensor([[3., 3.],
        [3., 3.]], grad_fn=<AddBackward0>)
```

`y` æ˜¯ç”±äºæ“ä½œé€ æˆçš„ï¼Œæ‰€ä»¥å®ƒæœ‰ä¸€ä¸ªåˆ›é€ è€…ã€‚

```python
print(y.creator)  # æŠ¥é”™ï¼Œå·²æ›¿æ¢ä¸ºgrad_fn
print(y.grad_fn)
```

<u>è¾“å‡º</u>:

```python
<AddBackward0 object at 0x00000226055E8940>
```

å¯¹yè¿›è¡Œæ›´å¤šçš„æ“ä½œ

```python
z = y * y * 3
out = z.mean()
print(z,out)
```

<u>è¾“å‡º:</u>

```python
tensor([[27., 27.],
        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)
```

**æ¢¯åº¦**

```python
out.backward()
```

æ‰“å°æ¢¯åº¦ d(out)/dx

```python
print(x.grad)
```

<u>è¾“å‡º:</u>

```python
tensor([[4.5000, 4.5000],
        [4.5000, 4.5000]])
```



è‡ªåŠ¨æ±‚å¯¼å¯ä»¥åšå¾ˆå¤šç–¯ç‹‚çš„äº‹æƒ…

```python
x = torch.rand(3)
x = Variable(x, requires_grad= True)
y = x * 2
while y.data.norm()< 1000:
    y = y * 2
    
print(y)
```

è§£é‡Šï¼š

`y.data.norm()`æ˜¯ç”¨æ¥æ±‚yçš„äºŒèŒƒæ•°

yçš„äºŒèŒƒæ•°å°äº1000çš„çº¦æŸæ¡ä»¶ä¸‹ï¼Œyçš„å…¬å¼å…¶å®æ˜¯ `y = 1024*x`



<u>è¾“å‡ºï¼š</u>

```python
tensor([591.5636, 884.0807, 773.9807], grad_fn=<MulBackward0>)
```

```python
gradients = torch.FloatTensor([0.1, 1.0, 0.0001])
y.backward(gradients)
print(x.grad)
```

<u>è¾“å‡ºï¼š</u>

```python
 tensor([1.0240e+02, 1.0240e+03, 1.0240e-01])
```



# LeNetï¼š

![LeNet](PyTorchå­¦ä¹ ä¹‹è·¯/LeNet.png)



## æ˜¾ç¤ºCIFARæ•°æ®é›†å›¾ç‰‡

```python
import torchvision
import torchvision.transforms as transforms
import torch


transform = transforms.Compose([transforms.ToTensor(),      # è½¬ä¸ºtensor
                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # å½’ä¸€åŒ–
                                ])
trainset = torchvision.datasets.CIFAR10(root="./data", train=True, download=True, transform=transform)
print(len(trainset))
trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,
                                          shuffle=True, num_workers=2)

testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)
testloader = torch.utils.data.DataLoader(testset, batch_size=4,
                                          shuffle=False, num_workers=2)
classes = ('plane', 'car', 'bird', 'cat',
           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')
# img, target = trainset[0]
# print(img)

import matplotlib.pyplot as plt
import numpy as np
def imshow(img):
    img =img / 2 + 0.5  # unnormalize
    npimg = img.numpy()
    plt.imshow(np.transpose(npimg, (1,2,0)))
    plt.show()

if __name__ == '__main__':           # å¼€å¯å¤šè¿›ç¨‹
    dataiter = iter(trainloader)
    images, labels = dataiter.next()
    imshow(torchvision.utils.make_grid(images))
    print(' '.join('%5s'%classes[labels[j]] for j in range(4)))
```



## å®šä¹‰ç½‘ç»œ

ç­‰å…ˆæŠŠåŸºç¡€å†™å®Œå†ç»§ç»­è¡¥å……ğŸ˜„



æœªå®Œå¾…ç»­ï¼ï¼ï¼

----

